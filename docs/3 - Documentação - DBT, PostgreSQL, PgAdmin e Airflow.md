# DocumentaÃ§Ã£o TÃ©cnica: Arquitetura de Dados com Airbyte, Airflow, DBT e PostgreSQL

**Autor:** Gustavo Lemos dos Santos (Arquiteto de Dados)  
**Data:** 24/06/2025

---

## SumÃ¡rio

1. [VisÃ£o Geral da Arquitetura](#1-visÃ£o-geral-da-arquitetura)  
2. [Componentes Principais](#2-componentes-principais)  
3. [Relacionamento entre Componentes](#3-relacionamento-entre-componentes)  
4. [Deploy no EC2 com Docker Compose](#4-deploy-no-ec2-com-docker-compose)  
5. [Requisitos de Rede e Acesso](#5-requisitos-de-rede-e-acesso)  

---

## 1. VisÃ£o Geral da Arquitetura

A arquitetura contempla uma esteira de ingestÃ£o, transformaÃ§Ã£o e disponibilizaÃ§Ã£o de dados baseada em:

- ExtraÃ§Ã£o com **Airbyte**
- OrquestraÃ§Ã£o com **Apache Airflow**
- TransformaÃ§Ãµes SQL com **DBT**
- Armazenamento em **PostgreSQL** via **Amazon RDS**
- VisualizaÃ§Ã£o via **Power BI**
- GovernanÃ§a com **OpenMetadata**
- Infraestrutura versionada com **GitHub**, **Docker** e **Azure DevOps**

---

## 2. Componentes Principais

### ğŸ”¸ Fontes de Dados

- **AWS S3** â€“ Dados brutos em arquivos JSON/parquet.
- **Oracle / SQL Server** â€“ Bancos relacionais legados.

---

### ğŸ”¹ Airbyte

Ferramenta de **EL**(Extract and Loading Only) para ingestÃ£o de dados com conectores prontos.

- Executa DAGs de ingestÃ£o prÃ³pria sem necessidade do uso do Airflow.
- Insere dados na **Landing Zone** no PostgreSQL.

---

### ğŸ”¹ Apache Airflow

Motor de orquestraÃ§Ã£o que coordena os pipelines de:

- TransformaÃ§Ã£o (DBT)
- GeraÃ§Ã£o de relatÃ³rios e paralelizaÃ§Ã£o com outras ferramentas se necessÃ¡rio

Utiliza DAGs organizadas em pastas por frequÃªncia e domÃ­nio.

---

### ğŸ”¹ DBT (Data Build Tool)

Executa transformaÃ§Ãµes SQL em cima dos dados da Landing Zone e gera modelos na **Persistence Zone**:

- `models/` contÃ©m os arquivos `.sql` com lÃ³gica de negÃ³cio.
- `dbt_project.yml` define estrutura e configuraÃ§Ãµes de ambiente.

---

### ğŸ”¹ PostgreSQL (Amazon RDS)

Serve como:

- Armazenamento da **Landing Zone**
- Banco intermediÃ¡rio e final da **Persistence Zone**
- Base para consumo por Power BI e outros consumidores

---

### ğŸ”¹ Power BI

Consome os dados transformados no schema final do PostgreSQL para geraÃ§Ã£o de relatÃ³rios e dashboards.

---

### ğŸ”¹ OpenMetadata

CatÃ¡logo de dados para:

- DocumentaÃ§Ã£o tÃ©cnica
- Nomenclatura de schemas
- GovernanÃ§a de ativos

---

### ğŸ”¹ Azure DevOps / GitHub

- RepositÃ³rio de DAGs e arquivos DBT
- Pipelines de CI/CD para atualizaÃ§Ã£o de artefatos no EC2 via Docker

---

## 3. Relacionamento entre Componentes

```plaintext
[S3 / Oracle / SQL Server]
         |
     [Airbyte] --> [PostgreSQL: landing]
         |
     [Airflow DAG de IngestÃ£o]
         |
     [DBT (via DAG de TransformaÃ§Ã£o)]
         |
     [PostgreSQL: persistence] --> [Power BI / Consumo]
         |
 [OpenMetadata] cataloga schemas e ativos
````

* As DAGs do Airflow executam as etapas de ingestÃ£o e transformaÃ§Ã£o.
* DBT transforma os dados e organiza em camadas semÃ¢nticas.
* Os dados finalizados sÃ£o consumidos por ferramentas de BI.

---

## 4. Deploy no EC2 com Docker Compose

### ğŸ”§ PrÃ©-requisitos

* InstÃ¢ncia EC2 (Amazon Linux ou Ubuntu)
* Docker e Docker Compose instalados
* Porta 8080 (Airflow), 5050 (pgAdmin), 5432 (Postgres) liberadas no Security Group

### ğŸ“¦ Etapas

#### 1. Instalar Docker e Docker Compose

```bash
# Docker
sudo yum install -y docker
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user
exit  # reconectar

# Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

#### 2. Subir ambiente

Estrutura de diretÃ³rios esperada:

```
project/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ plugins/
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ dbt_project/
â”œâ”€â”€ docker-compose.yml
```

Com o arquivo `docker-compose.yml` fornecido, execute:

```bash
cd project/
docker-compose up -d
```

#### 3. Acessos

* Airflow: `http://<ip_publico>:8080`
* pgAdmin: `http://<ip_publico>:5050`
* PostgreSQL: `5432` (usar com DBT e pgAdmin)

---

## 5. Requisitos de Rede e Acesso

### ğŸ” Portas a liberar no Security Group da EC2:

| Porta | ServiÃ§o        |
| ----- | -------------- |
| 22    | SSH            |
| 8080  | Airflow Web UI |
| 5050  | pgAdmin        |
| 5432  | PostgreSQL     |

### ğŸ‘¤ Acesso

* Airflow: usuÃ¡rio criado via DAG de inicializaÃ§Ã£o (`admin:admin`)
* pgAdmin: `admin@admin.com` / `admin`
* DBT: usa conexÃ£o via `profiles.yml` para conectar ao Postgres
* Dados sÃ£o organizados em:

  * `landing_dominio_squad_entidade`
  * `dominio_squad_entidade_final`

---

## 6. OrganizaÃ§Ã£o de DAGs

```
airflow/dags/
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ dag_diaria.py
â”‚   â”œâ”€â”€ dag_semanal.py
â”‚   â””â”€â”€ dag_mensal.py
â”œâ”€â”€ transformation/
â”‚   â”œâ”€â”€ dag_dbt_clientes.py
â”‚   â””â”€â”€ dag_dbt_vendas.py
```

---

## 7. Observabilidade

* **Grafana:** leitura de logs e mÃ©tricas do Airflow e Postgres
* **CloudWatch:** monitoramento de custos e uso
* **Secrets Manager:** armazenar senhas sensÃ­veis

---

## 8. Exemplo de ExecuÃ§Ã£o DBT

```sql
-- models/dominio_squad_atividade_usuarios.sql
WITH base AS (
  SELECT *
  FROM {{ ref('raw_usuarios') }}
)
SELECT
  id,
  COUNT(*) AS acessos,
  RANK() OVER (ORDER BY COUNT(*) DESC) AS rank_atividade
FROM base
GROUP BY id
```

---

## 9. RepositÃ³rio e CI/CD

* CÃ³digo versionado em Git
* Pull requests disparam pipelines no Azure DevOps via action
* AtualizaÃ§Ãµes sÃ£o empacotadas com Docker e aplicadas no EC2

**Importe: configurar um git clone deste repositÃ³rio inicialmente no ec2 com os serviÃ§os funcionais e para Pull Requests de novas dags e dbt procedures desenvolver um action para realizar um pull no repositÃ³rio jÃ¡ presente no EC2 e realizar uma atualizaÃ§Ã£o dos containers DBT e Airflow Squeduler**

**Importante: Em nÃ­vel de Poc estÃ¡ sendo utilizado o postgreSQL em container, mas recomenda-se que seja usado um RDS Aurora Aws em casos de ambiente de produÃ§Ã£o alÃ©m de uma possÃ­vel estratÃ©gia de nÃ£o segregar todos os containers dentro de um EC2 apenas.**

---

## 10. GovernanÃ§a

* Nome de schemas:

  * `ingestion_dominio_squad_entidade`
  * `dominio_squad_entidade_final`
* Todos os ativos sÃ£o catalogados no OpenMetadata

---


